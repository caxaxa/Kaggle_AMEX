{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport gc\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nimport random\n\nimport warnings \nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:22:56.242119Z","iopub.execute_input":"2022-08-20T03:22:56.242748Z","iopub.status.idle":"2022-08-20T03:22:57.456754Z","shell.execute_reply.started":"2022-08-20T03:22:56.242627Z","shell.execute_reply":"2022-08-20T03:22:57.455529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(42)\nplt.style.use('fivethirtyeight')\nwarnings.filterwarnings('ignore')\nsns.color_palette(\"flare\", as_cmap=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:22:57.458795Z","iopub.execute_input":"2022-08-20T03:22:57.459194Z","iopub.status.idle":"2022-08-20T03:22:57.494183Z","shell.execute_reply.started":"2022-08-20T03:22:57.459159Z","shell.execute_reply":"2022-08-20T03:22:57.493101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loding Data","metadata":{}},{"cell_type":"code","source":"dataframe = pd.read_feather('../input/amexfeather/train_data.ftr')\ndataframe = dataframe.groupby('customer_ID').tail(1).set_index('customer_ID')\n\n# limit for testing\ndataframe = dataframe.head(5000)","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:22:57.495677Z","iopub.execute_input":"2022-08-20T03:22:57.496079Z","iopub.status.idle":"2022-08-20T03:23:23.279077Z","shell.execute_reply.started":"2022-08-20T03:22:57.496042Z","shell.execute_reply":"2022-08-20T03:23:23.277778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Missing values","metadata":{}},{"cell_type":"code","source":"null_vals = dataframe.isna().sum().sort_values(ascending=False)\nnull_vals[null_vals > 0 ]","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:23:23.281654Z","iopub.execute_input":"2022-08-20T03:23:23.282097Z","iopub.status.idle":"2022-08-20T03:23:23.304210Z","shell.execute_reply.started":"2022-08-20T03:23:23.282055Z","shell.execute_reply":"2022-08-20T03:23:23.302860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title(\"Distribution of null values\")\nnull_vals[null_vals > 0 ].plot(kind = 'hist');","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:23:23.305968Z","iopub.execute_input":"2022-08-20T03:23:23.306380Z","iopub.status.idle":"2022-08-20T03:23:23.679537Z","shell.execute_reply.started":"2022-08-20T03:23:23.306344Z","shell.execute_reply":"2022-08-20T03:23:23.678502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(40,10))\nplt.title(\"Null value count\")\nplt.xlabel(\"Columns\")\nplt.ylabel(\"Count\")\nnull_vals[null_vals > 0 ].plot(kind=\"bar\");","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:23:23.681262Z","iopub.execute_input":"2022-08-20T03:23:23.681923Z","iopub.status.idle":"2022-08-20T03:23:24.888010Z","shell.execute_reply.started":"2022-08-20T03:23:23.681881Z","shell.execute_reply":"2022-08-20T03:23:24.886734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target Imbalance","metadata":{}},{"cell_type":"code","source":"sns.countplot(\n    dataframe[\"target\"].values,\n).set_xlabel(\"Target\");","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:23:24.889781Z","iopub.execute_input":"2022-08-20T03:23:24.890193Z","iopub.status.idle":"2022-08-20T03:23:25.082651Z","shell.execute_reply.started":"2022-08-20T03:23:24.890155Z","shell.execute_reply":"2022-08-20T03:23:25.081238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:23:25.084663Z","iopub.execute_input":"2022-08-20T03:23:25.085238Z","iopub.status.idle":"2022-08-20T03:23:32.133268Z","shell.execute_reply.started":"2022-08-20T03:23:25.085177Z","shell.execute_reply":"2022-08-20T03:23:32.131902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#change datetime to timestamp\ndataframe['S_2'] = dataframe[['S_2']].apply(lambda x: x[0].timestamp(), axis=1).astype(int)\ndataframe['S_2']","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:23:32.134775Z","iopub.execute_input":"2022-08-20T03:23:32.135552Z","iopub.status.idle":"2022-08-20T03:23:32.260566Z","shell.execute_reply.started":"2022-08-20T03:23:32.135508Z","shell.execute_reply":"2022-08-20T03:23:32.259248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\ntrain_dataframe = dataframe.drop(val_dataframe.index)\n\nprint(\n    \"Using %d samples for training and %d for validation\"\n    % (len(train_dataframe), len(val_dataframe))\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:23:32.266291Z","iopub.execute_input":"2022-08-20T03:23:32.267473Z","iopub.status.idle":"2022-08-20T03:23:32.288900Z","shell.execute_reply.started":"2022-08-20T03:23:32.267410Z","shell.execute_reply":"2022-08-20T03:23:32.287722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataframe_to_dataset(dataframe):\n    dataframe = dataframe.copy()\n    labels = dataframe.pop(\"target\")\n    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n    ds = ds.shuffle(buffer_size=len(dataframe))\n    return ds\n\n\ntrain_ds = dataframe_to_dataset(train_dataframe)\nval_ds = dataframe_to_dataset(val_dataframe)","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:23:32.290623Z","iopub.execute_input":"2022-08-20T03:23:32.290999Z","iopub.status.idle":"2022-08-20T03:23:32.870514Z","shell.execute_reply.started":"2022-08-20T03:23:32.290963Z","shell.execute_reply":"2022-08-20T03:23:32.869224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x, y in train_ds.take(1):\n    print(\"Input:\", x)\n    print(\"Target:\", y)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:23:32.872255Z","iopub.execute_input":"2022-08-20T03:23:32.872799Z","iopub.status.idle":"2022-08-20T03:23:33.459349Z","shell.execute_reply.started":"2022-08-20T03:23:32.872744Z","shell.execute_reply":"2022-08-20T03:23:33.457737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = train_ds.batch(32)\nval_ds = val_ds.batch(32)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:23:33.461162Z","iopub.execute_input":"2022-08-20T03:23:33.462639Z","iopub.status.idle":"2022-08-20T03:23:33.480787Z","shell.execute_reply.started":"2022-08-20T03:23:33.462562Z","shell.execute_reply":"2022-08-20T03:23:33.478903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pip install tensorflow.keras.layers -U","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:23:33.482925Z","iopub.execute_input":"2022-08-20T03:23:33.483730Z","iopub.status.idle":"2022-08-20T03:23:33.490386Z","shell.execute_reply.started":"2022-08-20T03:23:33.483682Z","shell.execute_reply":"2022-08-20T03:23:33.489118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import IntegerLookup\nfrom tensorflow.keras.layers import Normalization\nfrom tensorflow.keras.layers import StringLookup\n\n\ndef encode_numerical_feature(feature, name, dataset):\n    # Create a Normalization layer for our feature\n    normalizer = Normalization()\n\n    # Prepare a Dataset that only yields our feature\n    feature_ds = dataset.map(lambda x, y: x[name])\n    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n\n    # Learn the statistics of the data\n    normalizer.adapt(feature_ds)\n\n    # Normalize the input feature\n    encoded_feature = normalizer(feature)\n    return encoded_feature\n\n\ndef encode_categorical_feature(feature, name, dataset, is_string):\n    lookup_class = StringLookup if is_string else IntegerLookup\n    # Create a lookup layer which will turn strings into integer indices\n    lookup = lookup_class(output_mode=\"binary\")\n\n    # Prepare a Dataset that only yields our feature\n    feature_ds = dataset.map(lambda x, y: x[name])\n    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n\n    # Learn the set of possible string values and assign them a fixed integer index\n    lookup.adapt(feature_ds)\n\n    # Turn the string input into integer indices\n    encoded_feature = lookup(feature)\n    return encoded_feature\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:23:33.494239Z","iopub.execute_input":"2022-08-20T03:23:33.495484Z","iopub.status.idle":"2022-08-20T03:23:33.508653Z","shell.execute_reply.started":"2022-08-20T03:23:33.495416Z","shell.execute_reply":"2022-08-20T03:23:33.507569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset contains aggregated profile features for each customer at each statement date. Features are anonymized and normalized, and fall into the following general categories:\n\nD_* = Delinquency variables\nS_* = Spend variables\nP_* = Payment variables\nB_* = Balance variables\nR_* = Risk variables\nwith the following features being categorical:\n\n['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n\nYour task is to predict, for each customer_ID, the probability of a future payment default (target = 1).\n\nNote that the negative class has been subsampled for this dataset at 5%, and thus receives a 20x weighting in the scoring metric.","metadata":{}},{"cell_type":"code","source":"inputs = dataframe.columns.tolist()\n#del dataframe\n#gc.collect()\n#with the following features being categorical:\n\ncategoricals  = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_66', 'D_68']\n\nas_string = ['D_63' ,'D_64']\n\nexclude = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68','target']\n\n\n\n#list of all numerical \n\n#apparently there is no simpler sinthax to remove list of elements from a list\n\nnumericals = [x for x in inputs if x not in exclude]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:23:33.512307Z","iopub.execute_input":"2022-08-20T03:23:33.513508Z","iopub.status.idle":"2022-08-20T03:23:33.524876Z","shell.execute_reply.started":"2022-08-20T03:23:33.513465Z","shell.execute_reply":"2022-08-20T03:23:33.523457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build a model\n","metadata":{}},{"cell_type":"code","source":"# Categorical features encoded as integers\nvar_inputs_numericals = {}\nvar_encoded = {}\nfor var_num in numericals:\n    var_inputs_numericals[var_num] =  keras.Input(shape=(1,), name=var_num)\n    var_encoded[var_num] = encode_numerical_feature(var_inputs_numericals[var_num], var_num, train_ds)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T03:23:33.526495Z","iopub.execute_input":"2022-08-20T03:23:33.527062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categorical features encoded as integers\nvar_inputs_categoricals = {}\nfor var_num in categoricals:\n    var_inputs_categoricals[var_num] =  keras.Input(shape=(1,), name=var_num, dtype=\"int64\")\n    var_encoded[var_num] = encode_categorical_feature(var_inputs_categoricals[var_num], var_num, train_ds, False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categorical feature encoded as string\nvar_imput_string = {}\nfor var_num in as_string:\n    var_imput_string[var_num] =  keras.Input(shape=(1,), name=var_num, dtype=\"string\")\n    var_encoded[var_num] = encode_categorical_feature(var_imput_string[var_num], var_num, train_ds, True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var_inputs_numericals['S_2']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nall_features = layers.concatenate(input_list)\n\nx = layers.Dense(32, activation=\"relu\")(all_features)\nx = layers.Dropout(0.5)(x)\noutput = layers.Dense(1, activation=\"sigmoid\")(x)\nmodel = keras.Model(inputs, output)\nmodel.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# `rankdir='LR'` is to make the graph horizontal.\nkeras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_ds, epochs=50, validation_data=val_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#inference exampple\n\nsample = {\n    \"age\": 60,\n    \"sex\": 1,\n    \"cp\": 1,\n    \"trestbps\": 145,\n    \"chol\": 233,\n    \"fbs\": 1,\n    \"restecg\": 2,\n    \"thalach\": 150,\n    \"exang\": 0,\n    \"oldpeak\": 2.3,\n    \"slope\": 3,\n    \"ca\": 0,\n    \"thal\": \"fixed\",\n}\n\ninput_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\npredictions = model.predict(input_dict)\n\nprint(\n    \"This particular patient had a %.1f percent probability \"\n    \"of having a heart disease, as evaluated by our model.\" % (100 * predictions[0][0],)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submissions\n\nFit Submission to model\n\n","metadata":{}},{"cell_type":"code","source":"submit = pd.read_csv('../input/amex-default-prediction/sample_submission.csv')\nsubmit['prediction'] = 0\n\nfor df in dfs:\n    submit['prediction'] += df['prediction']\n    \nsubmit['prediction'] /= 4\n\nsubmit.to_csv('mean_submission.csv', index=None)\n\n\nsubmit = pd.read_csv('../input/amex-default-prediction/sample_submission.csv')\nsubmit['prediction'] = 0\n\nfor df in dfs:\n    submit['prediction'] += rankdata(df['prediction'])/df.shape[0]\n    \nsubmit['prediction'] /= 4\n\nsubmit.to_csv('rank_submission.csv', index=None)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights = [0.52, 0.87, 0.95, 0.57, 1, 0.8]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv('../input/amex-default-prediction/sample_submission.csv')\nsubmit['prediction'] = 0\n\nfor df, weight in zip(dfs, weights):\n    submit['prediction'] += (df['prediction'] * weight)\n    \nsubmit['prediction'] /= np.sum(weights)\n\nsubmit.to_csv('mean_submission.csv', index=None)\n\n \nsubmit = pd.read_csv('../input/amex-default-prediction/sample_submission.csv')\nsubmit['prediction'] = 0\n\nfor df, weight in zip(dfs, weights):\n    submit['prediction'] += (rankdata(df['prediction'])/df.shape[0]) * weight\n    \nsubmit['prediction'] /= 4\n\nsubmit.to_csv('submission.csv', index=None)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}